{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORiBaKBq9O5ElW22OZGzlc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/10Zee/CAD-Project-/blob/main/data_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inkuFaNPoQ3l"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import resample\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from itertools import cycle\n",
        "\n",
        "\n",
        "def filter_raw_data(breast_data, image_data):\n",
        "\n",
        "    # Join dataframes on PatientID\n",
        "    data = pd.merge(breast_data, image_data, left_on=['Accession_Number', 'Breast'], right_on=['Accession_Number', 'laterality'], suffixes=('', '_image_data'))\n",
        "\n",
        "    # Remove columns from image_data that also exist in breast_data\n",
        "    for col in breast_data.columns:\n",
        "        if col + '_image_data' in data.columns:\n",
        "            data.drop(col + '_image_data', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "    data = data[data['Has_Unknown'] == False]\n",
        "\n",
        "    # Reset the index\n",
        "    data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    data = upsample_minority(data)\n",
        "\n",
        "    return data\n",
        "\n",
        "def upsample_minority(data):\n",
        "    # Group data by ['Accession_Number', 'Breast'] and get the first entry for 'Has_Malignant' to determine the class\n",
        "    grouped_data = data.groupby(['Accession_Number', 'Breast']).agg({'Has_Malignant': 'first'})\n",
        "\n",
        "    # Determine the minority class (1 for malignant, 0 for benign)\n",
        "    minority_class = 1 if grouped_data['Has_Malignant'].mean() < 0.5 else 0\n",
        "\n",
        "    # Filter the groups belonging to the minority and majority classes\n",
        "    minority_groups = grouped_data[grouped_data['Has_Malignant'] == minority_class].index.tolist()\n",
        "    majority_groups = grouped_data[grouped_data['Has_Malignant'] != minority_class].index.tolist()\n",
        "\n",
        "    # Determine the difference in count between majority and minority classes\n",
        "    count_diff = len(majority_groups) - len(minority_groups)\n",
        "\n",
        "    # If the classes are already balanced, return the original data\n",
        "    if count_diff == 0:\n",
        "        return data\n",
        "\n",
        "    # Select groups from the minority class to duplicate\n",
        "    minority_data = data[data.set_index(['Accession_Number', 'Breast']).index.isin(minority_groups)]\n",
        "\n",
        "    # Create an iterator to cycle through the minority_data groups\n",
        "    group_cycle = cycle(minority_data.groupby(['Accession_Number', 'Breast']))\n",
        "\n",
        "    # Duplicate the necessary number of groups from the minority class to achieve balance\n",
        "    duplicated_data = pd.concat([next(group_cycle)[1] for _ in range(count_diff)], ignore_index=True)\n",
        "\n",
        "    # Find the maximum Accession_Number to generate new Accession_Numbers for duplicated rows\n",
        "    max_acc_number = data['Accession_Number'].max()\n",
        "\n",
        "    # Generate new Accession_Numbers for the duplicated rows\n",
        "    new_acc_numbers = range(max_acc_number + 1, max_acc_number + 1 + count_diff)\n",
        "    acc_number_mapping = dict(zip(duplicated_data['Accession_Number'].unique(), new_acc_numbers))\n",
        "    duplicated_data['Accession_Number'] = duplicated_data['Accession_Number'].map(acc_number_mapping)\n",
        "\n",
        "    # Concatenate the original data with the duplicated data\n",
        "    upsampled_data = pd.concat([data, duplicated_data], ignore_index=True)\n",
        "\n",
        "    return upsampled_data\n",
        "\n",
        "\n",
        "\n",
        "def create_bags(data, min_size, max_size, root_dir):\n",
        "    unique_patient_ids = data['Accession_Number'].unique()\n",
        "\n",
        "    bag_files = []\n",
        "    bag_labels = []\n",
        "    bag_ids = []\n",
        "    id = 0  # initialize bag id\n",
        "\n",
        "    for patient_id in tqdm(unique_patient_ids):\n",
        "        patient_data = data[data['Accession_Number'] == patient_id]\n",
        "\n",
        "        # Exclude bags that are outside the size range\n",
        "        if not (min_size <= len(patient_data) <= max_size):\n",
        "            continue\n",
        "\n",
        "        bag_file = []  # temporary lists to hold file names and labels for this bag\n",
        "        bag_label = []\n",
        "\n",
        "        for _, row in patient_data.iterrows():\n",
        "            filename = os.path.join(root_dir, row['ImageName'])\n",
        "            label = int(row['Has_Malignant'])\n",
        "            bag_file.append(filename)\n",
        "            bag_label.append(label)\n",
        "\n",
        "        bag_files.append(np.array(bag_file))  # convert to numpy array and append to bag_files\n",
        "        bag_labels.append(np.array(bag_label))  # convert to numpy array and append to bag_labels\n",
        "        bag_ids.append(id * np.ones(len(bag_file), dtype=int))  # create id array and append to bag_ids\n",
        "\n",
        "        id += 1  # increment bag id for the next bag\n",
        "\n",
        "    return bag_files, bag_labels, bag_ids\n",
        "\n",
        "\n",
        "\n",
        "def count_bag_labels(bag_labels):\n",
        "    positive_bag_count = 0\n",
        "    negative_bag_count = 0\n",
        "\n",
        "    for labels in bag_labels:\n",
        "        # Assuming a bag is positive if it contains at least one positive instance\n",
        "        if np.any(labels == 1):\n",
        "            positive_bag_count += 1\n",
        "        else:\n",
        "            negative_bag_count += 1\n",
        "\n",
        "    return positive_bag_count, negative_bag_count\n",
        "\n",
        "def process_single_image(row, root_dir, output_dir, resize_and_pad):\n",
        "    img_name = row['ImageName']\n",
        "    input_path = os.path.join(f'{root_dir}images/', img_name)\n",
        "    output_path = os.path.join(output_dir, img_name)\n",
        "\n",
        "    if os.path.exists(output_path):  # Skip images that are already processed\n",
        "        return\n",
        "\n",
        "    image = Image.open(input_path)\n",
        "    image = resize_and_pad(image)\n",
        "    image.save(output_path)\n",
        "\n",
        "def preprocess_and_save_images(data, root_dir, output_dir, image_size, fill=0):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    resize_and_pad = ResizeAndPad(image_size, fill)\n",
        "    data_rows = [row for _, row in data.iterrows()]  # Convert the DataFrame to a list of rows\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
        "        futures = {executor.submit(process_single_image, row, root_dir, output_dir, resize_and_pad): row for row in data_rows}\n",
        "\n",
        "        with tqdm(total=len(futures)) as pbar:\n",
        "            for future in as_completed(futures):\n",
        "                future.result()  # We don't actually use the result, but this will raise any exceptions\n",
        "                pbar.update()\n",
        "\n",
        "class GrayscaleToRGB:\n",
        "    def __call__(self, img):\n",
        "        if len(img.getbands()) == 1:  # If image is grayscale\n",
        "            img = transforms.functional.to_pil_image(np.stack([img] * 3, axis=-1))\n",
        "        return img\n",
        "\n",
        "class ResizeAndPad:\n",
        "    def __init__(self, output_size, fill=0):\n",
        "        assert isinstance(output_size, int)\n",
        "        self.output_size = output_size\n",
        "        self.fill = fill\n",
        "\n",
        "    def __call__(self, img):\n",
        "        w, h = img.size\n",
        "        if h > w:\n",
        "            new_h, new_w = self.output_size, int(self.output_size * (w / h))\n",
        "        else:\n",
        "            new_h, new_w = int(self.output_size * (h / w)), self.output_size\n",
        "        img = transforms.functional.resize(img, (new_h, new_w))\n",
        "\n",
        "        diff = self.output_size - new_w if h > w else self.output_size - new_h\n",
        "        padding = [diff // 2, diff // 2]\n",
        "\n",
        "        # If the difference is odd, add the extra padding to the end\n",
        "        if diff % 2 != 0:\n",
        "            padding[1] += 1\n",
        "\n",
        "        # Use the padding values for the left/right or top/bottom\n",
        "        padding = (padding[0], 0, padding[1], 0) if h > w else (0, padding[0], 0, padding[1])\n",
        "        img = transforms.functional.pad(img, padding, fill=self.fill)\n",
        "        return img\n",
        "\n",
        "\n",
        "\n",
        "def prepare_all_data(export_location, case_study_data, breast_data, image_data, cropped_images, img_size, min_bag_size, max_bag_size):\n",
        "\n",
        "    print(\"Preprocessing Data...\")\n",
        "    data = filter_raw_data(breast_data, image_data)\n",
        "\n",
        "    #Cropping images\n",
        "    preprocess_and_save_images(data, export_location, cropped_images, img_size)\n",
        "\n",
        "    # Split the data into training and validation sets\n",
        "    train_patient_ids = case_study_data[case_study_data['valid'] == 0]['Patient_ID']\n",
        "    val_patient_ids = case_study_data[case_study_data['valid'] == 1]['Patient_ID']\n",
        "    train_data = data[data['Patient_ID'].isin(train_patient_ids)].reset_index(drop=True)\n",
        "    val_data = data[data['Patient_ID'].isin(val_patient_ids)].reset_index(drop=True)\n",
        "\n",
        "    #data.to_csv(f'{env}/testData.csv')\n",
        "\n",
        "    bags_train, bags_train_labels_all, bags_train_ids = create_bags(train_data, min_bag_size, max_bag_size, cropped_images)\n",
        "    bags_val, bags_val_labels_all, bags_val_ids = create_bags(val_data, min_bag_size, max_bag_size, cropped_images)\n",
        "\n",
        "    files_train = np.concatenate( bags_train )\n",
        "    ids_train = np.concatenate( bags_train_ids )\n",
        "    labels_train = np.array([1 if np.any(x == 1) else 0 for x in bags_train_labels_all], dtype=np.float32)\n",
        "\n",
        "    files_val = np.concatenate( bags_val )\n",
        "    ids_val = np.concatenate( bags_val_ids )\n",
        "    labels_val = np.array([1 if np.any(x == 1) else 0 for x in bags_val_labels_all], dtype=np.float32)\n",
        "\n",
        "    print(f'There are {len(files_train)} files in the training data')\n",
        "    print(f'There are {len(files_val)} files in the validation data')\n",
        "    malignant_count, non_malignant_count = count_bag_labels(labels_train)\n",
        "    print(f\"Number of Malignant Bags: {malignant_count}\")\n",
        "    print(f\"Number of Non-Malignant Bags: {non_malignant_count}\")\n",
        "\n",
        "    return files_train, ids_train, labels_train, files_val, ids_val, labels_val\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BagOfImagesDataset(TUD.Dataset):\n",
        "\n",
        "    def __init__(self, filenames, ids, labels, normalize=True):\n",
        "        self.filenames = filenames\n",
        "        self.labels = from_numpy(labels)\n",
        "        self.ids = from_numpy(ids)\n",
        "        self.normalize = normalize\n",
        "        #self.imsize = imsize\n",
        "        # Normalize\n",
        "        if normalize:\n",
        "            self.tsfms = T.Compose([\n",
        "                T.RandomVerticalFlip(),\n",
        "                T.RandomHorizontalFlip(),\n",
        "                T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "                T.RandomAffine(\n",
        "                    degrees=(-20, 20),  # Random rotation between -10 and 10 degrees\n",
        "                    translate=(0.05, 0.05),  # Slight translation\n",
        "                    scale=(0.95, 1.05),  # Slight scaling\n",
        "                ),\n",
        "                T.ToTensor(),\n",
        "\n",
        "                T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "            ])\n",
        "        else:\n",
        "            self.tsfms = T.Compose([\n",
        "                T.ToTensor(),\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(torch.unique(self.ids))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        where_id = self.ids == index\n",
        "        files_this_bag = self.filenames[where_id]\n",
        "\n",
        "        # Define a transform to resize images to a common size (e.g., 672x959)\n",
        "        #resize_transform = T.Compose([T.Resize((672, 959)), T.ToTensor()])\n",
        "\n",
        "        # Modify the data loading part of your code\n",
        "        #data = torch.stack([\n",
        "            #self.tsfms(resize_transform(Image.open(fn).convert(\"RGB\"))) for fn in files_this_bag\n",
        "        #]).cuda()\n",
        "        #(T.Resize((672, 959))\n",
        "        data = torch.stack([\n",
        "            self.tsfms(T.Resize((672, 959))(Image.open(fn).convert(\"RGB\"))) for fn in files_this_bag\n",
        "        ]).cuda()\n",
        "        #data = torch.stack([\n",
        "          #  self.tsfms(Image.open(fn).convert(\"RGB\")) for fn in files_this_bag\n",
        "        #]).cuda()\n",
        "\n",
        "        labels = self.labels[index]\n",
        "\n",
        "        return data, labels\n",
        "\n",
        "    def show_image(self, index, img_index=0):\n",
        "        # Get the transformed image tensor and label\n",
        "        data, labels = self.__getitem__(index)\n",
        "\n",
        "        # Select the specified image from the bag\n",
        "        img_tensor = data[img_index]\n",
        "\n",
        "        # If the images were normalized, reverse the normalization\n",
        "        if self.normalize:\n",
        "            mean = torch.tensor([0.485, 0.456, 0.406]).to(img_tensor.device)\n",
        "            std = torch.tensor([0.229, 0.224, 0.225]).to(img_tensor.device)\n",
        "            img_tensor = img_tensor * std[:, None, None] + mean[:, None, None]  # Unnormalize\n",
        "\n",
        "        # Convert the image tensor to a PIL Image\n",
        "        img = TF.to_pil_image(img_tensor.cpu())\n",
        "\n",
        "        # Display the image and label\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Label: {labels}')\n",
        "        plt.axis('off')  # Hide the axis\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def n_features(self):\n",
        "        return self.data.size(1)\n",
        "\n",
        "def collate_custom(batch):\n",
        "    batch_data = []\n",
        "    batch_bag_sizes = [0]\n",
        "    batch_labels = []\n",
        "\n",
        "    for sample in batch:\n",
        "        batch_data.append(sample[0])\n",
        "        batch_bag_sizes.append(sample[0].shape[0])\n",
        "        batch_labels.append(sample[1])\n",
        "\n",
        "    out_data = torch.cat(batch_data, dim = 0).cuda()\n",
        "    bagsizes = torch.IntTensor(batch_bag_sizes).cuda()\n",
        "    out_bag_starts = torch.cumsum(bagsizes,dim=0).cuda()\n",
        "    out_labels = torch.stack(batch_labels).cuda()\n",
        "\n",
        "    return (out_data, out_bag_starts), out_labels"
      ]
    }
  ]
}